{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1607d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/deep-rl-class/blob/main/unit1/unit1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "sound_file = 'telephone-ring-02.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc16099",
   "metadata": {},
   "source": [
    "```\n",
    "!pip3 install pyvirtualdisplay\n",
    "!pip install gym[box2d]\n",
    "!pip install stable-baselines3[extra]\n",
    "!pip install huggingface_sb3\n",
    "!pip install pyglet\n",
    "!pip install ale-py==0.7.4 # To overcome an issue with gym (https://github.com/DLR-RM/stable-baselines3/issues/875)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Virtual display\n",
    "from pyvirtualdisplay import Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\n",
    "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167544b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ea28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246455bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285fea47",
   "metadata": {},
   "source": [
    "### Step 5: Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "2**11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = gym.make('LunarLander-v2')\n",
    "#env = make_vec_env('LunarLander-v2', n_envs=2048) # no tensorboard support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_baselines3.common.utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f87b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c anaconda tensorflow-gpu\n",
    "import tensorflow as tf\n",
    "#import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2bc235",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    policy = 'MlpPolicy', \n",
    "    env = env,\n",
    "    learning_rate=0.00025, \n",
    "    n_steps=2048, \n",
    "    batch_size=1024, \n",
    "    n_epochs=10, \n",
    "    gamma=0.99, \n",
    "    gae_lambda=0.95, \n",
    "    clip_range=0.2, \n",
    "    clip_range_vf=None, \n",
    "    normalize_advantage=True, \n",
    "    ent_coef=0.0, \n",
    "    vf_coef=0.5, \n",
    "    max_grad_norm=0.5, \n",
    "    use_sde=False, \n",
    "    sde_sample_freq=- 1, \n",
    "    target_kl=None, \n",
    "    tensorboard_log=None, \n",
    "    create_eval_env=False, \n",
    "    policy_kwargs=None, \n",
    "    verbose=0, \n",
    "    seed=None, \n",
    "    device='cuda', \n",
    "    _init_setup_model=True\n",
    ")\n",
    "\n",
    "print(dt.now())\n",
    "# SOLUTION\n",
    "# Train it for 500,000 timesteps\n",
    "model.learn(total_timesteps=25000000)\n",
    "print(dt.now())\n",
    "# Save the model\n",
    "model_name = \"ppo-LunarLander-v2\"\n",
    "model.save(model_name)\n",
    "\n",
    "\n",
    "#@title\n",
    "eval_env = gym.make(\"LunarLander-v2\")\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ca709",
   "metadata": {},
   "source": [
    "### vukpetar parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6af576",
   "metadata": {},
   "outputs": [],
   "source": [
    "2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e725c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "2**21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6582be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "2097152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7359a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed():\n",
    "    np.random.seed()\n",
    "    return np.random.randint(0, 2**32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3687321",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = get_seed()\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67452d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "# rm -rf ./logs/\n",
    "#log_dir = \"./logs/\" + dt.now().strftime(\"%Y%m%d-%H%M%S\")+'/'\n",
    "log_dir = \"./logs/\"\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae33c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d768d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting additional values in tensorboard.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=0):\n",
    "        super(TensorboardCallback, self).__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Log scalar value (here a random variable)\n",
    "        value = np.random.random()\n",
    "        self.logger.record('random_value', value)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb44d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    policy = 'MlpPolicy', \n",
    "    env = env,\n",
    "    learning_rate=0.00029, \n",
    "    n_steps=2048, \n",
    "    batch_size=2**22, \n",
    "    n_epochs=8, \n",
    "    gamma=0.999, \n",
    "    gae_lambda=0.98, \n",
    "    clip_range=0.2, \n",
    "    clip_range_vf=None, \n",
    "    normalize_advantage=True, \n",
    "    ent_coef=0.1, \n",
    "    vf_coef=0.01, \n",
    "    max_grad_norm=0.5, \n",
    "    use_sde=False, \n",
    "    sde_sample_freq=- 1, \n",
    "    target_kl=None, \n",
    "    tensorboard_log=log_dir, \n",
    "    create_eval_env=False, \n",
    "    policy_kwargs=None, \n",
    "    verbose=2, \n",
    "    seed=seed, \n",
    "    device='cuda', \n",
    "    _init_setup_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb086ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(\n",
    "    policy = 'MlpPolicy', \n",
    "    env = env,\n",
    "    learning_rate=0.00035, \n",
    "    verbose=0, \n",
    "    seed=seed, \n",
    "    tensorboard_log=log_dir,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758052ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(\n",
    "    policy,\n",
    "    env,\n",
    "    learning_rate=0.00011,\n",
    "    buffer_size=1000000,\n",
    "    learning_starts=100000,\n",
    "    batch_size=32,\n",
    "    tau=1.0,\n",
    "    gamma=0.99,\n",
    "    train_freq=4,\n",
    "    gradient_steps=1,\n",
    "    replay_buffer_class=None,\n",
    "    replay_buffer_kwargs=None,\n",
    "    optimize_memory_usage=False,\n",
    "    target_update_interval=10000,\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.05,\n",
    "    max_grad_norm=10,\n",
    "    tensorboard_log=log_dir,\n",
    "    create_eval_env=False,\n",
    "    policy_kwargs=None,\n",
    "    verbose=0,\n",
    "    seed=seed,\n",
    "    device='cuda',\n",
    "    _init_setup_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt.now())\n",
    "# SOLUTION\n",
    "# Train it for 500,000 timesteps\n",
    "#model.learn(total_timesteps=50000000)\n",
    "#model.learn(total_timesteps=500000)\n",
    "model.learn(total_timesteps=1000000, tb_log_name=\"first_run\")\n",
    "print(dt.now())\n",
    "# Save the model\n",
    "model_name = \"ppo-LunarLander-v2\"\n",
    "model.save(model_name)\n",
    "\n",
    "\n",
    "#@title\n",
    "eval_env = gym.make(\"LunarLander-v2\")\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd8821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e01c8a",
   "metadata": {},
   "source": [
    "### Step 8: Publish our trained model on the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a09613",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f071ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50577a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from huggingface_sb3 import package_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058807ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE the variables you've just defined two cells above\n",
    "# Define the name of the environment\n",
    "env_id = \"LunarLander-v2\"\n",
    "\n",
    "# TODO: Define the model architecture we used\n",
    "model_architecture = \"PPO\"\n",
    "\n",
    "## Define a repo_id\n",
    "## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
    "## CHANGE WITH YOUR REPO ID\n",
    "repo_id = \"format37/ppo-LunarLander-v2\"\n",
    "\n",
    "## Define the commit message\n",
    "commit_message = \"Upload PPO LunarLander-v2 trained agent\"\n",
    "\n",
    "# Create the evaluation env\n",
    "eval_env = DummyVecEnv([lambda: gym.make(env_id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8321c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install x264=='1!152.20180717' ffmpeg=4.0.2 -c conda-forge\n",
    "# https://stackovergo.com/ru/q/2654785/unknown-encoder-libx264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6523a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE the package_to_hub function you've just filled here\n",
    "package_to_hub(model=model, # Our trained model\n",
    "               model_name=model_name, # The name of our trained model \n",
    "               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n",
    "               env_id=env_id, # Name of the environment\n",
    "               eval_env=eval_env, # Evaluation Environment\n",
    "               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
    "               commit_message=commit_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-rl-class",
   "language": "python",
   "name": "deep-rl-class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
